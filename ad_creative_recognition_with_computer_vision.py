# -*- coding: utf-8 -*-
"""Ad Creative Recognition with computer Vision.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m8tpbNrlaJqxg1Xw2ApGWBt7yYZHrqxr
"""

# Install required packages
!pip install tensorflow opencv-python-headless matplotlib

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import cv2
import matplotlib.pyplot as plt
import os

# Load a sample dataset (CIFAR-10)
from tensorflow.keras.datasets import cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# For the sake of this example, let's consider classes 0 (airplane) as 'ad' and 1 (automobile) as 'non-ad'
ad_classes = [0, 1]  # Only using two classes for simplicity

# Filter dataset to only include the two classes
train_filter = np.isin(y_train, ad_classes)
test_filter = np.isin(y_test, ad_classes)

x_train, y_train = x_train[train_filter.flatten()], y_train[train_filter.flatten()]
x_test, y_test = x_test[test_filter.flatten()], y_test[test_filter.flatten()]

# Convert class labels to binary: 0 -> ad (0), 1 -> non-ad (1)
y_train = np.where(y_train == 0, 0, 1)
y_test = np.where(y_test == 0, 0, 1)

# Normalize pixel values to be between 0 and 1
x_train = x_train / 255.0
x_test = x_test / 255.0

# Define the model architecture
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

history = model.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=10,
    batch_size=32,
    callbacks=[early_stopping]
)

# Plot the training history
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.show()

# Evaluate the model on the test set
loss, accuracy = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

# Load and preprocess the sample image from the given path
sample_image_path = '/content/images.jpeg'

def load_and_preprocess_image(image_path):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB
    image = cv2.resize(image, (32, 32))  # Resize to match the input shape of the model
    image = image / 255.0  # Normalize pixel values to be between 0 and 1
    return np.expand_dims(image, axis=0)  # Add batch dimension

sample_image = load_and_preprocess_image(sample_image_path)

# Function to predict if an image is an ad creative
def is_ad_creative(image):
    features = model.predict(image)
    threshold = 0.5  # Threshold for classification
    is_ad = features > threshold
    return is_ad[0][0]

# Predict for the sample image
prediction = is_ad_creative(sample_image)
print(f"The sample image is classified as: {'Ad Creative' if prediction else 'Non-Ad Creative'}")

# Display the image with the prediction
def display_image_with_prediction(image_path, prediction):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.imshow(image)
    plt.title(f'Prediction: {"Ad Creative" if prediction else "Non-Ad Creative"}')
    plt.axis('off')
    plt.show()

# Display the sample image with the prediction
display_image_with_prediction(sample_image_path, prediction)